# Welcome to the test results of Stock Prediction

Hi! We are group 12 and we are testing a [system that predicts stock prices](https://github.com/lokesh45/StockPrediction).

## Description of the source repository

TODO

## Method: Test Plan

- Go to [TestPlan](https://docs.google.com/spreadsheets/d/1rQDUvgM1uNTLeklLOQzoprsNrLaTmgU-nL8uw30S_xw/edit#gid=632817659) spreadsheet.
- Assign keys to each user.
- Record the data generated from the participant. Each participant will perform following activities.
- Analyse the project based on Ease of use, Accuracy, Cost, Range of choice.
- Compare current project with other tools available online (Wallet Investor, AIStockFinder)
- Report bugs(if found)
- Review the project on scale 1(Low) to 5(High).
- Utilize the data and analyse the feedback received from each participant.
- Generate aggregated rating for the entire project based on Ease of use, Accuracy, Cost, Range of choice.

## How to setup: from cloning to deploying on Heroku

TODO

## Materials

First, each user was asked to fill the pre-survey form to gauge how much they are used to with the AI stock finder context. Later users were asked to register themselves on the Application we deployed on Heroku so they can perform certain tasks that were described in the tail of the README file. The previous step was repeated for the other two popular applications named Wallet Investor, AIStockFinder. After this user-filled post-experiment survey to gauge our application in terms of ease of use, user experience, etc.

Below are the tools used to perform anonymous experiments

- Deployed application: [App](https://radiant-falls-10905.herokuapp.com/)
- Platform used to deploy App: Heroku
- Project 3 GitHub Repository: [GitHub](https://github.com/git-ankit/MovieRecommender)
- For collecting responses: [Google form](https://docs.google.com/forms/d/e/1FAIpQLSfrOcLyx1ZxUexelyc2YJZB9imcJUHoP9oH8zVcHtOkJD-VYQ/viewform?usp=sf_link)
- Metrics used: [Test plan sheet](https://docs.google.com/spreadsheets/d/1rQDUvgM1uNTLeklLOQzoprsNrLaTmgU-nL8uw30S_xw/edit?usp=sharing)
- Tool used to setup meeting: [Zoom](https://zoom.us/)
- Code for plotting graphs: [Script](https://github.com/ssp4all/SE/tree/main/scriptsForAnalysis)



## Observations

TODO: Paste the screenshots and a brief factual introduction of the screenshot

## Analysis

IMPORTANT TODO

## Conclusion

TODO

## Threats to validity

- ##### Error from the participants
    One of the crucial feedback that we wanted was the ranking of the matrics concerning its weightage. We stated in the survey form to choose the option of how users feel about this metric while performing experiments. But some participants ranked all of them with the same number. This can significantly hurt the mean of feedback we received. This changes the overall ranking than what we got previously. Anyways, we can not get a significant result from only 5 rankings and all the means are very close to each other. Future studies on this subject need to take into consideration that users can make errors and to "beta" test their forms before sending out to the participants, so they can find areas that people might misunderstand.

- ##### Fedback from the user
    We could have asked the user who experimented on how we could improve the feedback process or more in detail like what was the most difficult thing use faced or what did they like more.

- ##### Comparision
    To compare the product we have developed we decided to go with two popular websites available in the market which are Wallet Investor, AIStockFinder. As there was no in-depth research behind both options hence, there may be changes the better comparable product might be available in the market.
        
- ##### Bias
    There are chances that for some users, the "Ease of use" starts from a medium, I mean the user has a mindset of giving the lowest value of medium and highest being high. So, for such a kind of user, we should have a normalized rating for each user.
